{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
    "df = pd.read_csv(data_url, sep=';')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1313\n",
      "[LightGBM] [Info] Number of data points in the train set: 3918, number of used features: 11\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score -5.565286\n",
      "[LightGBM] [Info] Start training from score -3.346083\n",
      "[LightGBM] [Info] Start training from score -1.212002\n",
      "[LightGBM] [Info] Start training from score -0.796864\n",
      "[LightGBM] [Info] Start training from score -1.739548\n",
      "[LightGBM] [Info] Start training from score -3.331694\n",
      "[LightGBM] [Info] Start training from score -6.663899\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttraining's multi_logloss: 1.18671\tvalid_1's multi_logloss: 1.22753\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's multi_logloss: 1.11397\tvalid_1's multi_logloss: 1.18303\n",
      "[3]\ttraining's multi_logloss: 1.05689\tvalid_1's multi_logloss: 1.15247\n",
      "[4]\ttraining's multi_logloss: 1.00895\tvalid_1's multi_logloss: 1.12565\n",
      "[5]\ttraining's multi_logloss: 0.968809\tvalid_1's multi_logloss: 1.10359\n",
      "[6]\ttraining's multi_logloss: 0.933517\tvalid_1's multi_logloss: 1.08375\n",
      "[7]\ttraining's multi_logloss: 0.900932\tvalid_1's multi_logloss: 1.06649\n",
      "[8]\ttraining's multi_logloss: 0.87238\tvalid_1's multi_logloss: 1.05303\n",
      "[9]\ttraining's multi_logloss: 0.843648\tvalid_1's multi_logloss: 1.04153\n",
      "[10]\ttraining's multi_logloss: 0.818705\tvalid_1's multi_logloss: 1.03019\n",
      "[11]\ttraining's multi_logloss: 0.795485\tvalid_1's multi_logloss: 1.02045\n",
      "[12]\ttraining's multi_logloss: 0.772685\tvalid_1's multi_logloss: 1.00955\n",
      "[13]\ttraining's multi_logloss: 0.752187\tvalid_1's multi_logloss: 1.00019\n",
      "[14]\ttraining's multi_logloss: 0.733212\tvalid_1's multi_logloss: 0.991005\n",
      "[15]\ttraining's multi_logloss: 0.714994\tvalid_1's multi_logloss: 0.983374\n",
      "[16]\ttraining's multi_logloss: 0.698751\tvalid_1's multi_logloss: 0.978461\n",
      "[17]\ttraining's multi_logloss: 0.682561\tvalid_1's multi_logloss: 0.973265\n",
      "[18]\ttraining's multi_logloss: 0.667528\tvalid_1's multi_logloss: 0.968474\n",
      "[19]\ttraining's multi_logloss: 0.652787\tvalid_1's multi_logloss: 0.963583\n",
      "[20]\ttraining's multi_logloss: 0.639195\tvalid_1's multi_logloss: 0.959841\n",
      "[21]\ttraining's multi_logloss: 0.626004\tvalid_1's multi_logloss: 0.954159\n",
      "[22]\ttraining's multi_logloss: 0.613823\tvalid_1's multi_logloss: 0.949776\n",
      "[23]\ttraining's multi_logloss: 0.60057\tvalid_1's multi_logloss: 0.946032\n",
      "[24]\ttraining's multi_logloss: 0.589555\tvalid_1's multi_logloss: 0.942566\n",
      "[25]\ttraining's multi_logloss: 0.578327\tvalid_1's multi_logloss: 0.939197\n",
      "[26]\ttraining's multi_logloss: 0.568152\tvalid_1's multi_logloss: 0.936849\n",
      "[27]\ttraining's multi_logloss: 0.558267\tvalid_1's multi_logloss: 0.933222\n",
      "[28]\ttraining's multi_logloss: 0.547929\tvalid_1's multi_logloss: 0.929955\n",
      "[29]\ttraining's multi_logloss: 0.538273\tvalid_1's multi_logloss: 0.929081\n",
      "[30]\ttraining's multi_logloss: 0.529235\tvalid_1's multi_logloss: 0.927218\n",
      "[31]\ttraining's multi_logloss: 0.520401\tvalid_1's multi_logloss: 0.927416\n",
      "[32]\ttraining's multi_logloss: 0.512318\tvalid_1's multi_logloss: 0.926522\n",
      "[33]\ttraining's multi_logloss: 0.503985\tvalid_1's multi_logloss: 0.925089\n",
      "[34]\ttraining's multi_logloss: 0.496026\tvalid_1's multi_logloss: 0.923996\n",
      "[35]\ttraining's multi_logloss: 0.487384\tvalid_1's multi_logloss: 0.921941\n",
      "[36]\ttraining's multi_logloss: 0.479226\tvalid_1's multi_logloss: 0.920918\n",
      "[37]\ttraining's multi_logloss: 0.471831\tvalid_1's multi_logloss: 0.920571\n",
      "[38]\ttraining's multi_logloss: 0.464301\tvalid_1's multi_logloss: 0.919048\n",
      "[39]\ttraining's multi_logloss: 0.457971\tvalid_1's multi_logloss: 0.919433\n",
      "[40]\ttraining's multi_logloss: 0.451334\tvalid_1's multi_logloss: 0.91837\n",
      "[41]\ttraining's multi_logloss: 0.445561\tvalid_1's multi_logloss: 0.916816\n",
      "[42]\ttraining's multi_logloss: 0.439208\tvalid_1's multi_logloss: 0.914581\n",
      "[43]\ttraining's multi_logloss: 0.432242\tvalid_1's multi_logloss: 0.913384\n",
      "[44]\ttraining's multi_logloss: 0.425799\tvalid_1's multi_logloss: 0.91378\n",
      "[45]\ttraining's multi_logloss: 0.419492\tvalid_1's multi_logloss: 0.912708\n",
      "[46]\ttraining's multi_logloss: 0.412854\tvalid_1's multi_logloss: 0.911101\n",
      "[47]\ttraining's multi_logloss: 0.407092\tvalid_1's multi_logloss: 0.911553\n",
      "[48]\ttraining's multi_logloss: 0.401108\tvalid_1's multi_logloss: 0.90924\n",
      "[49]\ttraining's multi_logloss: 0.39552\tvalid_1's multi_logloss: 0.907819\n",
      "[50]\ttraining's multi_logloss: 0.389702\tvalid_1's multi_logloss: 0.90797\n",
      "[51]\ttraining's multi_logloss: 0.384067\tvalid_1's multi_logloss: 0.907001\n",
      "[52]\ttraining's multi_logloss: 0.379188\tvalid_1's multi_logloss: 0.905009\n",
      "[53]\ttraining's multi_logloss: 0.374611\tvalid_1's multi_logloss: 0.904913\n",
      "[54]\ttraining's multi_logloss: 0.369958\tvalid_1's multi_logloss: 0.904805\n",
      "[55]\ttraining's multi_logloss: 0.364781\tvalid_1's multi_logloss: 0.904303\n",
      "[56]\ttraining's multi_logloss: 0.360022\tvalid_1's multi_logloss: 0.903639\n",
      "[57]\ttraining's multi_logloss: 0.355158\tvalid_1's multi_logloss: 0.903224\n",
      "[58]\ttraining's multi_logloss: 0.350299\tvalid_1's multi_logloss: 0.902585\n",
      "[59]\ttraining's multi_logloss: 0.345619\tvalid_1's multi_logloss: 0.904337\n",
      "[60]\ttraining's multi_logloss: 0.340942\tvalid_1's multi_logloss: 0.903377\n",
      "[61]\ttraining's multi_logloss: 0.3363\tvalid_1's multi_logloss: 0.903281\n",
      "[62]\ttraining's multi_logloss: 0.332454\tvalid_1's multi_logloss: 0.903384\n",
      "[63]\ttraining's multi_logloss: 0.327752\tvalid_1's multi_logloss: 0.903367\n",
      "[64]\ttraining's multi_logloss: 0.323549\tvalid_1's multi_logloss: 0.90404\n",
      "[65]\ttraining's multi_logloss: 0.320029\tvalid_1's multi_logloss: 0.903477\n",
      "[66]\ttraining's multi_logloss: 0.315331\tvalid_1's multi_logloss: 0.902904\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[67]\ttraining's multi_logloss: 0.311049\tvalid_1's multi_logloss: 0.903435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[68]\ttraining's multi_logloss: 0.307489\tvalid_1's multi_logloss: 0.903471\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's multi_logloss: 0.350299\tvalid_1's multi_logloss: 0.902585\n",
      "Accuracy: 0.6357142857142857\n"
     ]
    }
   ],
   "source": [
    "# 特徴量とラベルに分割\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "# クラスの値を調整\n",
    "y -= 3\n",
    "\n",
    "# データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# LightGBM用のデータセットに変換\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "# LightGBMのハイパーパラメータの設定\n",
    "params = {\n",
    "    'objective': 'multiclass', # 多クラス分類\n",
    "    'num_class': 7, # クラスの数\n",
    "    'metric': 'multi_logloss' # 損失関数にmulti_loglossを使用\n",
    "}\n",
    "verbose_eval = 1 # この数字を1にすると学習時のスコア推移がコマンドライン表示される\n",
    "\n",
    "# LightGBMモデルの学習\n",
    "model = lgb.train(params, train_data, num_boost_round=1000, \n",
    "                  valid_sets=[train_data, test_data],\n",
    "                  callbacks=[lgb.early_stopping(stopping_rounds=10, \n",
    "                                verbose=True), # early_stopping用コールバック関数\n",
    "                           lgb.log_evaluation(verbose_eval)] # コマンドライン出力用コールバック関数)\n",
    ")\n",
    "# テストデータでの予測\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = np.argmax(y_pred, axis=1) + 3 # 予測結果のクラスの値を調整\n",
    "y_test += 3 # テストデータのクラスの値を調整\n",
    "# 精度の評価\n",
    "accuracy = accuracy_score(y_test, y_pred_class)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
